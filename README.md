This NLP research paper emphasizes on the training and fine-tuning the pre-trained BERT model using this domain-specific data to improve the model's ability to understand and process specialised language. 
We make use of genz slang and emoji corpora mapped with their meaning, to show how using domain-specific corpora improves the model's ability to understand and process specialised language.
access here: https://docs.google.com/document/d/1LnwngaQrzEhYhCYKv78cZ_mfCDD81scQQ5QOymTllW0/edit?usp=sharing
